## 异步机制

Redis 阻塞点
  - 客户端
    - 网络 IO：Redis 使用了 IO 多路复用机制，避免网络等待状态，网络 IO 不是阻塞点
    - 键值对增删改查：高复杂命令、bigkey 删除操作可能产生阻塞（释放大量内存）
    - 数据库操作：清空数据库涉及删除和释放所有键值对，会阻塞
  - 磁盘
    - 生成 RDB 快照
    - 记录 AOF 日志
    - AOF 日志重写
    - Redis 涉及采用子进程的方式生成 RDB 文件和 AOF 重写，慢速磁盘 IO 不会阻塞
    - 直接记录 AOF 会根据不同写回策略落盘，如果大量的写操作需要记录 AOF 并同步写回，会阻塞
  - 主从节点
    - 主库生成
    - 传输 RDB 文件
    - 从库接收 RDB 文件
    - 加载 RDB
    - 清空数据库
    - 主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程
    - 从库在接收 RDB 后需要使用`flushdb`清空数据库，加载 RDB 到内存，会产生阻塞
  - 切片集群实例
    - 向其他实例传输哈希槽信息：哈希槽的信息量不大，而数据迁移是渐进式执行的，一般这两类操作对 Redis 主线程的阻塞风险不大
    - 数据迁移：迁移 bigkey 的话，就会造成主线程的阻塞

阻塞点
  - 集合全量查询和聚合操作：可以使用`SCAN`命令，分批读取数据，再在客户端进行聚合计算
  - bigkey 删除
  - 清空数据库
  - AOF 日志同步写
  - 从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载

如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作（客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作）

读操作属于关键操作，需要客户端返回具体的数据信息，所以集合全量查询和聚合操作不能异步

bigkey 删除和清空数据库不需要客户端获取具体数据，可以异步

AOF 日志同步写可以异步启动子线程执行，而不用让主线程等待

从库加载 RDB 时，从库需要提供数据服务就必须等待 RDB 加载完成，必须让从库的主线程执行，不能异步操作

### 异步子线程机制

Redis 主线程启动后，会使用操作系统提供的`pthread_create`函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行

主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成，此时真正的删除还没执行，等到后台子线程从任务队列读取任务后真正开始执行删除操作（lazy free/unlink）

当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完

### 异步删除的实现

主线程需要将删除任务传递给异步线程， 它是通过一个普通的双向链表来传递的。 因为链表需要支持多线程并发操作， 所以它需要有锁来保护。

执行懒惰删除时， Redis 将删除操作的相关参数封装成一个 bio_job 结构， 然后追加到链表尾部。 异步线程通过遍历链表摘取 job 元素来挨个执行异步任务。

```c
struct bio_job {
    time_t time; // 时间字段暂时没有使用， 应该是预留的
    void *arg1, *arg2, *arg3;
};
```

```c
    /* What we free changes depending on what arguments are set:
     * arg1 -> free the object at pointer.
     * arg2 & arg3 -> free two dictionaries (a Redis DB).
     * only arg3 -> free the skiplist. */
    if (job->arg1)
        // 释放一个普通对象， string/set/zset/hash 等等， 用于普通对象的异步删除
        lazyfreeFreeObjectFromBioThread(job->arg1);
    else if (job->arg2 && job->arg3)
        // 释放全局 redisDb 对象的 dict 字典和 expires 字典， 用于 flushdb
        lazyfreeFreeDatabaseFromBioThread(job->arg2, job->arg3);
    else if (job->arg3)
        // 释放 Cluster 的 slots_to_keys 对象， 参见源码篇的「基数树」小节
        lazyfreeFreeSlotsMapFromBioThread(job->arg3);
```

```c
void lazyfreeFreeObjectFromBioThread(robj *o) {

    decrRefCount(o); // 降低对象的引用计数， 如果为零， 就释放
    atomicDecr(lazyfree_objects, 1); // lazyfree_objects 为待释放对象的数量， 用于统计

}

// 减少引用计数
void decrRefCount(robj *o) {

    if (o - > refcount == 1) {
        // 该释放对象了
        switch (o - > type) {
            case OBJ_STRING:
                freeStringObject(o);
                break;
            case OBJ_LIST:
                freeListObject(o);
                break;
            case OBJ_SET:
                freeSetObject(o);
                break;
            case OBJ_ZSET:
                freeZsetObject(o);
                break;
            case OBJ_HASH:
                freeHashObject(o);
                break; // 释放 hash 对象， 继续追踪
            case OBJ_MODULE:
                freeModuleObject(o);
                break;
            case OBJ_STREAM:
                freeStreamObject(o);
                break;
            default:
                serverPanic("Unknown object type");
                break;
        }
        zfree(o);
    } else {
        if (o - > refcount <= 0) serverPanic("decrRefCount against refcount <= 0");
        if (o - > refcount != OBJ_SHARED_REFCOUNT) o - > refcount--; // 引用计数减 1
    }

}

// 释放 hash 对象
void freeHashObject(robj *o) {

    switch (o - > encoding) {
        case OBJ_ENCODING_HT:
            // 释放字典， 我们继续追踪
            dictRelease((dict * ) o - > ptr);
            break;
        case OBJ_ENCODING_ZIPLIST:
            // 如果是压缩列表可以直接释放
            // 因为压缩列表是一整块字节数组
            zfree(o - > ptr);
            break;
        default:
            serverPanic("Unknown hash encoding type");
            break;
    }

}

// 释放字典， 如果字典正在迁移中， ht[0] 和 ht[1] 分别存储旧字典和新字典
void dictRelease(dict *d)
{

    _dictClear(d, & d - > ht[0], NULL); // 继续追踪
    _dictClear(d, & d - > ht[1], NULL);
    zfree(d);

}

// 这里要释放 hashtable 了
// 需要遍历第一维数组， 然后继续遍历第二维链表， 双重循环
int _dictClear(dict *d, dictht *ht, void(callback)(void *)) {

    unsigned long i;

    /* Free all the elements */
    for (i = 0; i < ht - > size && ht - > used > 0; i++) {
        dictEntry * he, * nextHe;

        if (callback && (i & 65535) == 0) callback(d - > privdata);

        if ((he = ht - > table[i]) == NULL) continue;
        while (he) {
            nextHe = he - > next;
            dictFreeKey(d, he); // 先释放 key
            dictFreeVal(d, he); // 再释放 value
            zfree(he); // 最后释放 entry
            ht - > used--;
            he = nextHe;
        }
    }
    /* Free the table and the allocated cache structure */
    zfree(ht - > table); // 可以回收第一维数组了
    /* Re-initialize the table */
    _dictReset(ht);
    return DICT_OK; /* never fails */

}
```

### 队列安全

```c
void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3) {
    struct bio_job *job = zmalloc(sizeof(*job));

    job->time = time(NULL);
    job->arg1 = arg1;
    job->arg2 = arg2;
    job->arg3 = arg3;
    pthread_mutex_lock(&bio_mutex[type]); // 加锁
    listAddNodeTail(bio_jobs[type],job); // 追加任务
    bio_pending[type]++; // 计数
    pthread_cond_signal(&bio_newjob_cond[type]); // 唤醒异步线程
    pthread_mutex_unlock(&bio_mutex[type]); // 释放锁
}
```

异步线程需要对任务队列进行轮训处理，依次从链表表头摘取元素逐个处理。摘取元素的时候也需要加锁，摘出来之后再解锁。如果一个元素都没有，它需要等待，直到主线程来唤醒它继续工作。

```c
// 异步线程执行逻辑
void *bioProcessBackgroundJobs(void *arg) {
...
    pthread_mutex_lock(&bio_mutex[type]); // 先加锁
    ...
    // 循环处理
    while(1) {
        listNode *ln;

        /* The loop always starts with the lock hold. */
        if (listLength(bio_jobs[type]) == 0) {
            // 对列空，那就睡觉吧
            pthread_cond_wait(&bio_newjob_cond[type],&bio_mutex[type]);
            continue;
        }
        /* Pop the job from the queue. */
        ln = listFirst(bio_jobs[type]); // 获取队列头元素
        job = ln->value;
        /* It is now possible to unlock the background system as we know have
         * a stand alone job structure to process.*/
        pthread_mutex_unlock(&bio_mutex[type]); // 释放锁

        // 这里是处理过程，为了省纸，就略去了
        ...

        // 释放任务对象
        zfree(job);

        ...

        // 再次加锁继续处理下一个元素
        pthread_mutex_lock(&bio_mutex[type]);
        // 因为任务已经处理完了，可以放心从链表中删除节点了
        listDelNode(bio_jobs[type],ln);
        bio_pending[type]--; // 计数减 1
    }
```
