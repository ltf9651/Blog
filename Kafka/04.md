## Topic-Partition

分区有多副本机制，每个副本对应一个日志文件，每个日志文件对应一个至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等

### 主题管理

#### 创建主题

创建方式：通过 kafka-topics.sh 脚本进行创建

```sh
ls /tmp/kafka-logs/ | grep topic-create // 查看节点中创建的主题分区

[zk: localhost:2181/kafka(CONNECTED) 2] get /brokers/topics/topic-create
{"version":1,"partitions":{"2":[1,2],...}}
// 分区2分配了2个副本，分别在brokerId为1和2的broker节点中
```

同一分区中的多个副本必须分布在不同的 broker 中，才能提供有效的数据冗余，每个 broker 中都拥有所有分区的一个副本

`if-not-exists` 创建主题发生重名冲突时不作出任何处理

#### 分区副本的分配

- 创建主题时，通过`replica-assignment`指定分配方案
- 生产者的分区分配：为每条消息指定其所要发往的分区
- 消费者的分区分配：为消费者指定其可以消费消息的区间

#### 查看主题

``` sh
// 查看当前所有可用主题
bin/kafka-topics.sh --zookeeper localhost:2181/kafka -list

// 查看某个主题信息
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic1
topics-with-overrides 找出所有包含覆盖配置的主题
under-replicated-partitions 找出包含是小副本的分区
unavailable-partitions 查看主题中没有leader副本的分区，这些分区处于不可用状态
```

#### 修改主题

```sh
// 将分区数修改为3
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic1 --partitions 3
```

kafka 目前只支持增加分区数而不支持减少分区数

#### 配置管理

```sh
// 增加 cleanup.policy 和 max.message.bytes
bin/kafka-configs.sh --zookeeper localhost:2181/kafka --alter --entity-type topics topic-config --add-config cleanup.policy=compact,max.message.bytes=10000
```

#### 删除主题

``` sh
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --delete --topic topic1 --if-exists
```

删除本质上只是在 Zookeeper 中的 /admin/delete-topics 路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态，真正删除动作在 Kafka 控制器完成

删除操作不可逆

### 分区管理

#### 优先副本的选举

- 分区使用多副本机制提升可靠性，只有 leader 副本对外提供读写副本 follower 只负责在内部进行消息同步
- 当一个分区的 leader 不可用，需要从剩余的 follower 挑选出一个新的 leader，党员来的 leader 恢复后成为 follower
- 分区有多个副本，对于 broker，最多只能有一个副本
- 优先副本：AR 集合列表中的第一个副本
- 选举机制：通过一定的方式促使优先副本选举为 leader 副本，促进集群的负载均衡
- auto.leader.rebalance.enable：分区自动平衡，Kafka 控制器会启动一个定时任务，轮训所有的 broker 节点，计算每个 broker 的分区不平衡率，超过设定比值的会自动执行有限副本的选举动作（对性能有负面影响，可能造成客户端阻塞）
- 手动执行分区平衡：kafka-perferred-replica-election.sh

#### 分区重分配

- 当集群中的一个节点突然宕机下线，如果节点上的分区时单副本，那么这些分区就变成等不可用，节点恢复前这些数据处于丢失状态
- 如果是多副本，位于这个节点上的 leader 副本的角色会转交到集群的其他 follower 副本中
- Kafka 不会将失效的分区副本自动迁移到可用节点上
- kafka-reassign-partitions.sh 执行分区重分配工作，将失效节点数据转移到可用节点
- 重分配原理：先通过控制器为每个分区添加新副本，新的副本将从分区的 leader 副本那里复制同步所有的数据，复制完成后控制器删除就副本
- 重分配对集群性能有很大影响，需要占用额外的资源

#### 复制限流

- 实现方式
  1. kafka-config.sh
  1. kafka-reassign-partitions.sh
- follower.replication.throttled.rate：设置 follower 副本复制的速度
- leader.replication.throttled.rate：设置 leader 副本传输的速度
- follower.replication.throttled.replicas：被限制速度的主题所对应的 follower 副本列表
- leader.replication.throttled.replicas：被限制速度的主题所对应的 leader 副本列表

#### 修改副本因子

副本数可以减少

### 选择合适的分区数

#### 性能测试工具

```sh
// 向一个只有1个分区和1个副本的topic-1发送100W条消息，每条消息大小为1024B
bin/kafka-producer-perf-test.sh --topic topic-1 --num-records 1000000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1
```

#### 分区数量与性能（吞吐量）

- 分区时 Kafka 中最下的并行操作单元，对于 Producer，每一个分区的数据写入是完全可以并行化的；对于 Consumer，Kafka 只循序单个分区中的消息被一个消费者线程消费，一个消费组的消费并行度完全依赖于所消费的分区数
- 一味地增加分区数不能是吞吐量一直提升，如果分区数并不能一直增加，如果超过默认的配置值会引起 Kafka 进程的崩溃
- 分区数会占用文件描述符，一个进程所能支配的文件描述符是有限的
