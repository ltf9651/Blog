## 服务器并发处理能力

### 吞吐率：单位时间内服务器处理的请求数

- 最大吞吐率（Requests per second）：单位时间内服务器能够处理的最大请求数

- 压测前提条件
    - 并发用户数：某一时刻同时向服务器发送请求的用户总数
    - 总请求数：
    - 请求资源描述

![](https://github.com/ltf9651/Blog/blob/master/WebPerformance/picture/RPS.png)


### CPU并发计算

#### 进程
- 资源分配的最小单位
- 大多数进程的时间主要消耗在I/O操作
- 进程由内核调度，进程的目的是担当分配系统资源的实体
- 进程也可以认为是记录程序实例当前运行到什么程度的一组数据，多个进程通过不同的进程描述符与这些数据进行关联
- 每个进程都拥有独立的内存地址和生命周期，当子进程被父进程创建后，便将父进程地址空间的所有数据复制到自己的地址空间，完全继承父进程的上下文信息，它们之间可以通信又互不依赖，也无权干涉各自的地址空间
- 进程的创建使用folk()系统调用，在繁忙的服务器上频繁的创建进程其开销可能成为影响性能的主要因素

#### 线程
- 轻量级进程
- 操作系统调度（CPU调度）执行的最小单位
- 由于进程之间相互独立，各自维护庞大的地址空间和上下文信息，无法很好的低成本共享数据，当采用大量进程的Web服务器在处理大量并发请求时，内存的大量消耗会成为制约性能的因素。
- 进程优势：相互独立，稳定，健壮
- 轻量级进程：系统调用clone()创建，内核直接管理，像普通进程一样独立存在，各自拥有独立进程描述符，但是共享地址空间、打开的文件等，减少内存开销

#### 协程
- 比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源

#### 进程调度器
- 内核中的进程调度器维护着各种状态的的进程队列（Run Quene），包括所有可运行程序的队列和所有休眠进程和僵尸进程的队列
- 进程调度器决定下一个运行的进程，每个进程会告诉进程调度器进程运行的紧急情况，成为进程优先级
- 进程优先级除了由进程自身决定，进程调度器在进程运行时也可以动态调整
- 给每个CPU分配一个运行队列，互不影响，进程调度器负责将进程分配到合适的CPU

#### 进程切换
- 进程调度器在必要的时候挂起正在运行的进程，同时恢复以前挂起的某个进程，称为进程切换
- 一个进程被挂起的本质：将它在CPU寄存器中的数据取出暂时存入内核态堆栈
- 恢复本质：将它的数据重新装入CPU寄存器
- 减少进程切换有利于提升系统并发出能力

#### IOWait
- CPU空闲并且等待I/O操作完成的时间比例
- 性能监控工具：Nmon，Lighthttpd

#### 锁竞争
- 锁：防止资源竞争抢占导致数据错乱，保证线程安全
- 允许的情况下关闭Web服务器访问日志可大大减少锁等待的延迟时间

### 系统调用
- Linux进程设计运行模式
    - 用户态
    - 内核态
- 提高系统底层安全性和简化开发模型
- 系统调用涉及进程从用户态切换到内核态，导致一定的内存空间交换（上下文切换），所以开销昂贵

### 内存分配
- Apache（多进程模型）: 采用基于内存池策略的内存管理方案，在运行一开始就申请大量的内存作为内存池，随后只需从内存池中直接获取，不需要再次分配，内存管理更加安全，内存池在Apache关闭时释放
- 单进程: 使用多线程处理请求，使得多线程之间可以共享内存资源，内存使用量大大减少。同时使用分阶段的内存分配策略，按需分配，及时释放

### 持久连接（Keep-Alive)
- 短连接：建立连接后发送一份数据后马上断开，频繁的使用性能开销大
- 长连接：系统调用少，性能开销少，但是使用不当会导致Web服务器维护大量的空闲进程，影响性能

### DMA（Direct Memory Access)
可以不经过CPU而直接进行磁盘和内存的数据交换，降低了CPU的占有率，节省系统资源

### I/O

#### 同步阻塞I/O
- 阻塞：当前发起I/O操作的进程被阻塞（CPU无法被阻塞），**进程访问的数据尚未就绪，需要等待**
- 同步I/O阻塞：当进程调用到某些设计I/O操作的系统调用或者库函数（accept(),send(),recv()）时，进程便暂停下来，等待I/O操作完后再继续运行。
- 同步I/O：简单有效，可以和多进程结合有效的利用CPU资源，但是代价就是多进程的大量内存开销
- 等待时间：等待数据的就绪和等到数据的复制

#### 同步非阻塞I/O
- 不用等待数据的就绪
- 结合反复轮询尝试数据是否就绪，如果数据不可读写就立刻告诉进程，防止进程被阻塞，可以在一个进程同时处理多个I/O操作
- 由于需要不断轮询查看数据是否就绪，需要花费大量的CPU时间，使进程处于忙碌等待状态
- 非阻塞I/O只针对网络I/O有效，在socket选项中调用O_NONBLOCK，对于磁盘I/O，非阻塞无效
- 如果服务器要同时接受多个TCP连接的数据，就必须轮流对每个socket调用接收数据的方法，进程会浪费很多CPU时间用于检查socket

#### 多路I/O就绪通知
- 允许进程通过一种方法同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行数据访问
- 只帮助快速获得就绪文件描述符，当得知数据就绪后，就访问数据本身，仍要选择阻塞或非阻塞的访问方式。一般选择非阻塞方式，防止任何意外的等待组织整个进程

#### 内存映射
- 访问磁盘的方式：将内存中的某块地址空间和要指定的磁盘文件相关联，从而把对这块内存的访问转换为对磁盘文件的访问
- 提高I/O性能，使用mmap()代替read(),write()等系统调用建立内存和磁盘文件的关联，像访问内存一样访问文件
- 映射类型
    - 共有型：将任何对内存的写操作同步到磁盘文件，且所有映射到同一文件的进程都共享一个进程对映射内存的修改
    - 私有型：只可读文件

#### 直接I/O
- Linux2.6中，内存映射和直接访问文件没有差异，数据从进程用户态内存空间到磁盘都要经过两次复制：磁盘与内核缓冲区之间以及内核缓冲区与用户态内存空间
- 引入内核缓冲区的目的：提高磁盘文件的访问性能，读写发生在缓冲区，延迟刷入硬盘

#### 异步I/O
- 同步：主动请求并等待I/O操完毕，当数据就绪后在读写的时候必须阻塞
- 异步：主动请求数据后便可继续处理其他任务，随后等待I/O操作完毕的通知，进程在数据读写的时候不发生阻塞（当用户态进程调用库函数访问文件时，进行必要的快速注册，比如写入读写队列，然后函数马上返回）

### 服务器并发策略
- 所有到达服务器的请求都封装在IP包中，位于网卡的接受缓冲区，此时服务器需要不断的读取这些请求，然后进行处理，并将结果写到发送缓冲区
- 并发策略：让I/O操作和CPU金酸尽量重叠进行，一方面使CPU在I/O等待时不空闲，一方面使CPU在I/O调度上尽量少花费时间

#### 一个进程处理一个连接，非阻塞I/O
- fork：主进程负责accept()来自客户端的连接，一旦接受连接，马上fork()一个新的worker进程进行处理，处理结束后进程销毁
- prefork：主进程预先创建一定数量的子进程，每个请求由一个子进程完成，但是每个子进程可以处理多个请求，父进程只负责管理子进程，根据站点负载调节子进程的数量，相当于动态维护一个进程池

- accept策略
    - 主进程使用非阻塞accept()接收连接，当建立连接后，主进程将任务分配给空闲的子进程处理
    - 所有子进程使用阻塞accept()来竞争接收连接，一旦一个子进程建立连接后，将继续进行处理

#### 一个线程处理一个连接，非阻塞I/O
- 一个进程中创建多个线程处理请求，每个线程处理一个连接，可减少prefork模式太多进程的开销
- 线程由内核调度器管理，上下文切换开销依然存在
- 性能没有优势，较少使用

#### 一个进程处理多个连接，非阻塞I/O
- 多路I/O复用
- Nginx Woker